<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Infering neural and behavioral dynamics in delayed reach task · NeuroDynamics.jl</title><meta name="title" content="Infering neural and behavioral dynamics in delayed reach task · NeuroDynamics.jl"/><meta property="og:title" content="Infering neural and behavioral dynamics in delayed reach task · NeuroDynamics.jl"/><meta property="twitter:title" content="Infering neural and behavioral dynamics in delayed reach task · NeuroDynamics.jl"/><meta name="description" content="Documentation for NeuroDynamics.jl."/><meta property="og:description" content="Documentation for NeuroDynamics.jl."/><meta property="twitter:description" content="Documentation for NeuroDynamics.jl."/><meta property="og:url" content="https://elgazzarr.github.io/NeuroDynamics.jl/examples/Joint_mcmaze/"/><meta property="twitter:url" content="https://elgazzarr.github.io/NeuroDynamics.jl/examples/Joint_mcmaze/"/><link rel="canonical" href="https://elgazzarr.github.io/NeuroDynamics.jl/examples/Joint_mcmaze/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuroDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuroDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/1-setting_up_model/">Setting up a differentiable model</a></li><li><a class="tocitem" href="../../tutorials/2-building_latentUDE/">Constructing a LatentSDE</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../Modeling_HodkingHuxely/">Modeling single neuron</a></li><li><a class="tocitem" href="../Neural_mcmaze/">Infering neural dynamics in motor cortex</a></li><li class="is-active"><a class="tocitem" href>Infering neural and behavioral dynamics in delayed reach task</a><ul class="internal"><li><a class="tocitem" href="#1.-Loading-the-data-and-creating-the-dataloaders"><span>1. Loading the data and creating the dataloaders</span></a></li><li><a class="tocitem" href="#2.-Defining-the-model"><span>2. Defining the model</span></a></li><li><a class="tocitem" href="#3.-Training-the-model"><span>3. Training the model</span></a></li></ul></li><li><a class="tocitem" href="../Joint_area2bump/">Infering neural and behavioral dynamics in Area2 during perturbed reach task</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Infering neural and behavioral dynamics in delayed reach task</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Infering neural and behavioral dynamics in delayed reach task</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/elgazzarr/NeuroDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/elgazzarr/NeuroDynamics.jl/blob/main/docs/src/examples/Joint_mcmaze.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Joint-modeling-of-neural-and-behavioural-dynamics-during-dealyed-reach-task"><a class="docs-heading-anchor" href="#Joint-modeling-of-neural-and-behavioural-dynamics-during-dealyed-reach-task">Joint modeling of neural and behavioural dynamics during dealyed reach task</a><a id="Joint-modeling-of-neural-and-behavioural-dynamics-during-dealyed-reach-task-1"></a><a class="docs-heading-anchor-permalink" href="#Joint-modeling-of-neural-and-behavioural-dynamics-during-dealyed-reach-task" title="Permalink"></a></h1><p>In this example, we will show how to use the latentsde model to generate neural observations (spiking recordings of neurons in the dorsal premotor (PMd) and primary motor (M1) cortices) and behavioural observations (Hand velocity) of a monkey doing a dealyed reach task.  The data is available for download <a href="https://dandiarchive.org/#/dandiset/000128">here</a>.</p><pre><code class="language-julia hljs">using Pkg, Revise, Lux, LuxCUDA, CUDA, Random, DifferentialEquations, SciMLSensitivity, ComponentArrays, Plots, MLUtils, OptimizationOptimisers, LinearAlgebra, Statistics, Printf, PyCall, Distributions
using IterTools: ncycle
using NeuroDynamics
np = pyimport(&quot;numpy&quot;)
device = &quot;cpu&quot;
const dev = device == &quot;gpu&quot; ? gpu_device() : cpu_device()
</code></pre><h2 id="1.-Loading-the-data-and-creating-the-dataloaders"><a class="docs-heading-anchor" href="#1.-Loading-the-data-and-creating-the-dataloaders">1. Loading the data and creating the dataloaders</a><a id="1.-Loading-the-data-and-creating-the-dataloaders-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Loading-the-data-and-creating-the-dataloaders" title="Permalink"></a></h2><p>You can prepare the data yourself or use our preprocessed data staright away which is available <a href="https://drive.google.com/file/d/1J9">here</a></p><pre><code class="language-julia hljs">file_path = &quot;/Users/ahmed.elgazzar/Datasets/NLB/mc_maze.npy&quot; # Replace with your path to the dataset
data = np.load(file_path, allow_pickle=true)
Y_neural = permutedims(get(data[1], &quot;spikes&quot;) , [3, 2, 1])|&gt; Array{Float32}
Y_behaviour = permutedims(get(data[1], &quot;hand_vel&quot;) , [3, 2, 1])|&gt; Array{Float32}
n_neurons = size(Y_neural)[1]
n_neurons , n_timepoints, n_trials = size(Y_neural);
n_behviour = size(Y_behaviour)[1]
ts = range(0, 4, length=n_timepoints);
ts_input = repeat(ts, 1, n_trials) 
U = reshape(ts_input, (1, size(ts_input)...))|&gt; Array{Float32} 
n_ctrl = size(U)[1]
(U_train, Yn_train, Yb_train) , (U_test, Yn_test, Yb_test) = splitobs((U, Y_neural, Y_behaviour); at=0.7)
train_loader = DataLoader((U_train, Yn_train, Yb_train), batchsize=28, shuffle=true)
val_loader = DataLoader((U_test, Yn_test, Yb_test), batchsize=10, shuffle=true);</code></pre><h2 id="2.-Defining-the-model"><a class="docs-heading-anchor" href="#2.-Defining-the-model">2. Defining the model</a><a id="2.-Defining-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Defining-the-model" title="Permalink"></a></h2><ul><li>We will use a &quot;Recurrent_Encoder&quot; to infer the initial hidden state from a portion of the observations. </li><li>We will use a BlackBox (Neural) SDE with multiplicative noise to model the latent dynamics.</li><li>We will use a multi-headed decoder, one for the neural observations and one for behaviour.</li></ul><pre><code class="language-julia hljs">hp = Dict(&quot;n_states&quot; =&gt; 16, &quot;hidden_dim&quot; =&gt; 64, &quot;context_dim&quot; =&gt; 32, &quot;t_init&quot; =&gt; Int(0.8 * n_timepoints))
rng = Random.MersenneTwister(1234)
obs_encoder = Recurrent_Encoder(n_neurons, hp[&quot;n_states&quot;], hp[&quot;context_dim&quot;], 32, hp[&quot;t_init&quot;])
drift = Chain(Dense(hp[&quot;n_states&quot;], hp[&quot;hidden_dim&quot;], softplus), Dense(hp[&quot;hidden_dim&quot;], hp[&quot;n_states&quot;], tanh))
drift_aug = Chain(Dense(hp[&quot;n_states&quot;] + hp[&quot;context_dim&quot;] + n_ctrl, hp[&quot;hidden_dim&quot;], softplus), Dense(hp[&quot;hidden_dim&quot;], hp[&quot;n_states&quot;],tanh))
diffusion = Scale(hp[&quot;n_states&quot;], sigmoid, init_weight=identity_init(gain=0.1))
dynamics = SDE(drift, drift_aug, diffusion, EulerHeun(), saveat=ts, dt=ts[2]-ts[1])
obs_decoder = Chain(MLP_Decoder(hp[&quot;n_states&quot;], n_neurons, 64, 1, &quot;Poisson&quot;), Lux.BranchLayer(NoOpLayer(), Linear_Decoder(n_neurons, n_behviour,&quot;Gaussian&quot;)))

ctrl_encoder, ctrl_decoder = NoOpLayer(), NoOpLayer()
model = LatentUDE(obs_encoder, ctrl_encoder, dynamics, obs_decoder, ctrl_decoder, dev)
p, st = Lux.setup(rng, model)
p = p |&gt; ComponentArray{Float32};
</code></pre><h2 id="3.-Training-the-model"><a class="docs-heading-anchor" href="#3.-Training-the-model">3. Training the model</a><a id="3.-Training-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Training-the-model" title="Permalink"></a></h2><p>We will train the model using the AdamW optimizer with a learning rate of 1e-3 for 200 epochs. </p><pre><code class="language-julia hljs">function train(model::LatentUDE, p, st, train_loader, val_loader, epochs, print_every)
    
    epoch = 0
    L = frange_cycle_linear(epochs+1, 0.5f0, 1.0f0, 1, 0.3)
    losses = []
    θ_best = nothing
    best_metric = -Inf
    println(&quot;Training ...&quot;)

    function loss(p, u, y_n, y_b)
        u, y_n, y_b  = u |&gt; dev, y_n |&gt; dev, y_b |&gt; dev
        (ŷ_n, ŷ_b), _, x̂₀, kl_path = model(y_n, u, ts, p, st)
        batch_size = size(y_n)[end]
        neural_loss = - poisson_loglikelihood(ŷ_n, y_n)/batch_size
        behaviorual_loss = - normal_loglikelihood(ŷ_b..., y_b)
        obs_loss = neural_loss + behaviorual_loss
        kl_init = kl_normal(x̂₀[1], x̂₀[2])
        kl_path = mean(kl_path[end,:])
        kl_loss =  kl_path  +  kl_init
        l =  0.1*obs_loss + 10*L[epoch+1]*kl_loss
        return l, obs_loss, kl_loss
    end


    callback = function(opt_state, l, obs_loss , kl_loss)
        θ = opt_state.u
        push!(losses, l)
        if length(losses) % length(train_loader) == 0
            epoch += 1
        end

        if length(losses) % (length(train_loader)*print_every) == 0
            @printf(&quot;Current epoch: %d, Loss: %.2f, Observations_loss: %d, KL: %.2f\n&quot;, epoch, losses[end], obs_loss, kl_loss)
            u, y_n, y_b = first(train_loader) 
            (ŷ_n, ŷ_b), _, _ = predict(model, y_n, u, ts, θ, st, 20) 
            ŷ_n = dropdims(mean(ŷ_n, dims=4), dims=4)
            ŷ_b_m, ŷ_b_s = dropdims(mean(ŷ_b[1], dims=4), dims=4), dropdims(mean(ŷ_b[2], dims=4), dims=4)
            val_bps = bits_per_spike(ŷ_n, y_n)
            val_ll = normal_loglikelihood(ŷ_b_m, ŷ_b_s, y_b)
            @printf(&quot;Validation bits/spike: %.2f\n&quot;, val_bps)
            @printf(&quot;Validation behaviour log-likelihood: %.2f\n&quot;, val_ll)
            if val_ll &gt; best_metric
                best_metric = val_ll
                 θ_best = copy(θ)
                 @printf(&quot;**** Saving best model ****\n&quot;)
                end   
            d = plot_preds(y_b,  ŷ_b[1])
            display(d)

        end
        return false
    end

    adtype = Optimization.AutoZygote()
    optf = OptimizationFunction((p, _ , u, y_n, y_b) -&gt; loss(p, u, y_n, y_b), adtype)
    optproblem = OptimizationProblem(optf, p)
    result = Optimization.solve(optproblem, ADAMW(5e-4), ncycle(train_loader, epochs); callback)
    return model, θ_best
    
end
</code></pre><pre><code class="language-julia hljs">model, θ_best = train(model, p, st, train_loader, val_loader, 5000, 500);</code></pre><pre><code class="language-julia hljs">u, y_n, y_b = first(train_loader) 
(ŷ_n, ŷ_b), _, x = predict(model, y_n, u, ts, θ_best, st, 20)
sample = 8
ch = 9
ŷₘ = dropmean(ŷ_n, dims=4)
ŷₛ = dropmean(ŷ_n, dims=4)
dist = Poisson.(ŷₘ)
pred_spike = rand.(dist)
xₘ = dropmean(x, dims=4)
val_bps = bits_per_spike(ŷₘ, y_n)

p1 = plot(transpose(y_n[ch:ch,:,sample]), label=&quot;True Spike&quot;, lw=2)
p2 = plot(transpose(pred_spike[ch:ch,:,sample]), label=&quot;Predicted Spike&quot;, lw=2, color=&quot;red&quot;)
p3 = plot(transpose(ŷₘ[ch:ch,:,sample]), ribbon=transpose(ŷₛ[ch:ch,:,sample]), label=&quot;Infered rates&quot;, lw=2, color=&quot;green&quot;)

plot(p1, p2,p3, layout=(3,1), size=(800, 400), legend=:topleft)
</code></pre><pre><code class="language-julia hljs">savefig(&quot;spike_prediction.png&quot;)</code></pre><pre><code class="language-julia hljs">s = 13
plot_samples(ŷ_b[1], s)
plot!(transpose(y_b[:,:,s]), label=[&quot;True&quot; nothing], lw=2, color=&quot;red&quot;, legend=:topleft)
</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Neural_mcmaze/">« Infering neural dynamics in motor cortex</a><a class="docs-footer-nextpage" href="../Joint_area2bump/">Infering neural and behavioral dynamics in Area2 during perturbed reach task »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Wednesday 10 July 2024 03:38">Wednesday 10 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
